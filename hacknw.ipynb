{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nw.parser import NwParser\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from nw.settings import NW_SQL_PATH, ELASTIC_HOSTS, ELK_HOST\n",
    "# import pyelasticsearch\n",
    "from nw.loggers import logger\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import joblib\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "\n",
    "# es = pyelasticsearch.ElasticSearch('http://' + ELK_HOST)\n",
    "# engine = create_engine('sqlite:///{}'.format(NW_SQL_PATH))\n",
    "# df = pd.read_sql('select topic_html, topic_url from nwdump limit 100', engine)\n",
    "# parser = NwParser()\n",
    "\n",
    "     \n",
    "\n",
    "     \n",
    "# failed = [] \n",
    "# p_json = []\n",
    "# t_json = []\n",
    "# for i, (topic_url, topic_html) in enumerate(zip(df.topic_url, df.topic_html)):\n",
    "#     if i%1000 == 0:\n",
    "#         print('processed {}'.format(i))\n",
    "#     try:\n",
    "#         posts_json, topic_json = parser.topic_html_to_json(topic_html)\n",
    "#         p_json.append(posts_json)\n",
    "#         t_json.append(topic_json)\n",
    "        \n",
    "#     except:\n",
    "#         failed.append(topic_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun  parser.topic_html_to_json(df.topic_html.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.722222222222222"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 170000 * 0.1 ) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (item for sublist in l for item in sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_df = pd.DataFrame.from_records(itertools.chain(*posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py:1101: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['cites', 'forum_id', 'post_body', 'post_id', 'unique_post_id', 'user_href', 'user_name']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "posts_df.to_hdf('posts_all.h5','posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in posts_df.iterrows():\n",
    "    a = row\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_hdf('posts_all.h5','posts')\n",
    "\n",
    "h = df.head()\n",
    "h.to_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nw.parser import NwParser\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from nw.settings import NW_SQL_PATH, ELASTIC_HOSTS, ELK_HOST\n",
    "import pyelasticsearch\n",
    "from nw.loggers import logger\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "es = pyelasticsearch.ElasticSearch('http://' + ELK_HOST)\n",
    "engine = create_engine('sqlite:///{}'.format(NW_SQL_PATH))\n",
    "df = pd.read_sql('select  topic_html from nwdump limit 100', engine)\n",
    "\n",
    "\n",
    "# docs = [es.index_op(d, id=d.get('unique_post_id')) for d in collect]\n",
    "# for i, chun in enumerate(chunks(docs, int(len(docs) * .05))):\n",
    "#     logger.info('processing chunk {}'.format(i))\n",
    "#     res = es.bulk(chun, index='nw', doc_type='post')\n",
    "#     print(res)\n",
    "#     print('---' * 10)\n",
    "#     print(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['post_length'] = df.post_body.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df.user_name.isin(df.user_name.value_counts()[:2000].index)].groupby(df.user_name)['post_length'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.post_body.loc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5496160, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics_=joblib.load('t_json.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = pd.DataFrame.from_records(topics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_topics.to_hdf('topics_all.h5','topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nw.jobs import index_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-01 19:43:07,192 - nw-logger - INFO - RUNNING RE-INDEX-SCRAPE JOB for topics: [173498]\n",
      "2016-12-01 19:43:07,195 - nw-logger - INFO - Indexing topic 173498\n",
      "2016-12-01 19:43:07,198 - nw-logger - DEBUG - parsing topic number 173498\n",
      "2016-12-01 19:43:08,048 - nw-logger - INFO - {'forum_id': '/forum/4', 'topic_name': '#PizzaGate', 'topic_id': 173498, 'post_date': datetime.datetime(2016, 11, 20, 22, 39, 19)}\n",
      "2016-12-01 19:43:08,049 - nw-logger - INFO - ['{\"index\": {\"_id\": 173498}}\\n{\"forum_id\": \"/forum/4\", \"topic_name\": \"#PizzaGate\", \"topic_id\": 173498, \"post_date\": \"2016-11-20T22:39:19\"}']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_topics([173498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyelasticsearch import ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = ElasticSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es.search(\n",
    "{\n",
    "    \"sort\" : \n",
    "        { \"topic_id\" : {\"order\" : \"asc\"}},\n",
    "\n",
    "}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts = pd.read_hdf('/media/i008/duzy1/posts_all.h5')\n",
    "topic = pd.read_hdf('/media/i008/duzy1/topics_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144639, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = posts.merge(topic[['topic_id','topic_name']], on='topic_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import sqlite3\n",
    "from nw.loggers import logger\n",
    "from nw.parser import NwParser\n",
    "import datetime\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import json\n",
    "\n",
    "\n",
    "parser = NwParser()\n",
    "conn =sqlite3.connect('/media/i008/duzy1/nwdb.sqlite')\n",
    "\n",
    "def t_to_json(html):\n",
    "    try:\n",
    "        return parser.topic_html_to_json(html)\n",
    "    except:\n",
    "#         logger.info('--failed--')\n",
    "        pass\n",
    "\n",
    "select = conn.execute('select topic_html from nwdump')\n",
    "collect = []\n",
    "ii = 0\n",
    "for row in select:\n",
    "    if not ii%1000: \n",
    "        logger.info('{} -- {}'.format(datetime.datetime.utcnow(), ii))       \n",
    "    collect.append(t_to_json(row[0]))\n",
    "    ii+=1\n",
    "\n",
    "    \n",
    "joblib.dump(collect, 'all_posts_list.pickl')\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_records(flattened)\n",
    "df.to_hdf('allposts_new','posts')\n",
    "\n",
    "\n",
    "dx = df[:]\n",
    "dx.cites = dx.cites.apply(lambda x: json.dumps(x))\n",
    "dx.post_date = dx.post_date.astype(str)\n",
    "cnx = sqlite3.connect('nw_posts.sqlite')\n",
    "sql.to_sql(dx,'nw_posts', cnx, if_exists='replace', chunksize=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flattened_posts.pickl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattened = [item for sublist in filter(None,collect) for item in sublist]\n",
    "joblib.dump(flattened, 'flattened_posts.pickl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.read_sql('select * from nw_posts', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# d.user_name.value_counts()[:30].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/media/i008/duzy1/nw_data/nw_posts.hdf5', 'posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.head().to_html()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
